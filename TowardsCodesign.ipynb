{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10683b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77919377",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pionplus_1k.npy'\n",
    "file = open(filename, 'rb')\n",
    "mc_truth = np.load(file,allow_pickle=True) #Added Generator E and Angle\n",
    "data = np.load(file,allow_pickle=True)\n",
    "\n",
    "test_file = open('test.npy', 'rb')\n",
    "test_data = np.load(test_file,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9967b0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- ORIGINAL test.npy -------------------\n",
      "number of images in event 400\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------- ORIGINAL test.npy -------------------\")\n",
    "print('number of images in event', len(test_data[0]))\n",
    "#print(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f22c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- NEW .npy ----------------\n",
      "number of images in event 400\n",
      "(1000, 400)\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------- NEW .npy ----------------\")\n",
    "print('number of images in event', len(data[0]))\n",
    "#print(data[0][0])\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0898d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.007061"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_truth.item().get('true_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a86edf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images in event 400\n",
      "(400, 96, 6)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "#============ Original ============================\n",
    "X = []\n",
    "Y = []\n",
    "with open('test.npy', 'rb') as f:#wrong file for now\n",
    "#with open(filename, 'rb') as f:\n",
    "    data = np.load(f,allow_pickle=True)\n",
    "    ievt = 0\n",
    "    print('number of images in event', len(data[ievt]))\n",
    "    ## Here we loop over all \"images\", which are created by integrating HCAL sampling layers defing 3 sectors defined \n",
    "    ## by two z position that define boundary. Note for all images ECAL is the same (no longitudinal separation in ECAL)\n",
    "    for im in range(len(data[ievt])):\n",
    "        event = np.c_[data[ievt][im]['HCAL1_x'][0],data[ievt][im]['HCAL1_y'][0],data[ievt][im]['HCAL1_E'][0]]\n",
    "        depths = np.array([2*np.ones(len(data[ievt][im]['HCAL1_x'][0]))]).flatten()\n",
    "        if (len(data[ievt][im]['HCAL2_x'])>0):\n",
    "            event = np.concatenate([event,np.c_[data[ievt][im]['HCAL2_x'][0],data[ievt][im]['HCAL2_y'][0],data[ievt][im]['HCAL2_E'][0]]])\n",
    "            depths = np.concatenate([depths,np.array([3*np.ones(len(data[ievt][im]['HCAL2_x'][0]))]).flatten()])\n",
    "        if (len(data[ievt][im]['HCAL3_x'])>0):\n",
    "            event = np.concatenate([event,np.c_[data[ievt][im]['HCAL3_x'][0],data[ievt][im]['HCAL3_y'][0],data[ievt][im]['HCAL3_E'][0]]])\n",
    "            depths = np.concatenate([depths,np.array([4*np.ones(len(data[ievt][im]['HCAL3_x'][0]))]).flatten()])\n",
    "        event = np.concatenate([event,np.c_[data[ievt][im]['ECAL_x'],data[ievt][im]['ECAL_y'],data[ievt][im]['ECAL_E']]])\n",
    "        depths = np.concatenate([depths,np.array([1*np.ones(len(data[ievt][im]['ECAL_x']))]).flatten()])\n",
    "        event = np.insert(event, 3, depths,axis=1)\n",
    "        event = np.insert(event, 4, data[ievt][im]['boundary'][0]*np.ones(len(event)),axis=1) #better to make these global features, but I did not want to download the latest energyflow package\n",
    "        event = np.insert(event, 5, data[ievt][im]['boundary'][1]*np.ones(len(event)),axis=1)\n",
    "        X += [event]\n",
    "        trueenergy = 20.007061 #Miguel, please add this!\n",
    "        Y += [trueenergy]\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print(np.shape(X))\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58943f55-0cd5-4cac-8eab-c293ceb5455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awk_to_numpy_padded(awk_array,fill_val,ncell_max=1200,cell_axis=2,clip=True):\n",
    "\n",
    "    none_padded = ak.pad_none(ak.ArrayBuilder.snapshot(awk_array), ncell_max, axis=cell_axis, clip=True)\n",
    "    none_to_val = ak.fill_none(none_padded,fill_val,axis=cell_axis)\n",
    "    array = np.squeeze(ak.to_numpy(none_to_val))\n",
    "\n",
    "    return(array)\n",
    "\n",
    "ncell_max = 1200 #Root file indicates avg. of ~270 per ECal and HCal each. \n",
    "cell_axis = 2\n",
    "n_cell_variables = 6\n",
    "fill_val = np.zeros(n_cell_variables) #for zero paddin awkward array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d562c02-39c6-4271-8e21-8868602fb8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Events: 1000 N Images per Event: 400\n",
      "new numpy shape = (400, 1200, 6)\n",
      "X shape = (400, 1200, 6) ([Images X Events][Cells][XYEDBB])\n",
      "Y shape = (400,) [MC Truth Energy]\n"
     ]
    }
   ],
   "source": [
    "X_awk = ak.ArrayBuilder()\n",
    "X_awk.begin_list()\n",
    "Y = []\n",
    "\n",
    "with open(filename, 'rb') as f:\n",
    "#with open(\"test.npy\", 'rb') as f:\n",
    "    mc_truth = np.load(f,allow_pickle=True)\n",
    "    data = np.load(f,allow_pickle=True)\n",
    "    \n",
    "    print('N Events:', len(data),'N Images per Event:',len(data[0]))\n",
    "    \n",
    "    ievt=4\n",
    "    if not(ievt==999):\n",
    "    #for ievt in range(0,len(data)):\n",
    "    #for ievt in range(0,1):\n",
    "        \n",
    "        ## Here we loop over all events and then all \"images\", which are created by integrating HCAL sampling layers defing 3 sectors defined \n",
    "        ## by two z position that define boundary. Note for all images ECAL is the same (no longitudinal separation in ECAL)\n",
    "\n",
    "        for im in range(len(data[ievt])):\n",
    "            #FIXME: assumes ECAL is always hit...\n",
    "            event = np.c_[data[ievt][im]['ECAL_x'],data[ievt][im]['ECAL_y'],data[ievt][im]['ECAL_E']]\n",
    "            depths = np.array([1*np.ones(len(data[ievt][im]['ECAL_x']))]).flatten()\n",
    "            \n",
    "            if (ievt == im == 0):\n",
    "                print(\"ECAL X:\", np.shape(data[ievt][im]['ECAL_x']), \"+ ECAL Y\", np.shape(data[ievt][im]['ECAL_y']),\n",
    "                  \"+ ECAL E\", np.shape(data[ievt][im]['ECAL_E']),\"=\",np.shape(event), \"[using np.c_]\")\n",
    "\n",
    "            if (len(data[ievt][im]['HCAL1_x'])>0):\n",
    "                event = np.concatenate([event,np.c_[data[ievt][im]['HCAL1_x'][0],data[ievt][im]['HCAL1_y'][0],data[ievt][im]['HCAL1_E'][0]]])\n",
    "                depths = np.concatenate([depths,np.array([2*np.ones(len(data[ievt][im]['HCAL1_x'][0]))]).flatten()])\n",
    "            \n",
    "            if (len(data[ievt][im]['HCAL2_x'])>0):\n",
    "                event = np.concatenate([event,np.c_[data[ievt][im]['HCAL2_x'][0],data[ievt][im]['HCAL2_y'][0],data[ievt][im]['HCAL2_E'][0]]])\n",
    "                depths = np.concatenate([depths,np.array([3*np.ones(len(data[ievt][im]['HCAL2_x'][0]))]).flatten()])\n",
    "                \n",
    "            if (len(data[ievt][im]['HCAL3_x'])>0):\n",
    "                event = np.concatenate([event,np.c_[data[ievt][im]['HCAL3_x'][0],data[ievt][im]['HCAL3_y'][0],data[ievt][im]['HCAL3_E'][0]]])\n",
    "                depths = np.concatenate([depths,np.array([4*np.ones(len(data[ievt][im]['HCAL3_x'][0]))]).flatten()])\n",
    "            \n",
    "            if (ievt == im == 0):\n",
    "                print(\"HCAL X:\", np.shape(data[ievt][im]['HCAL3_x']), \"+ HCAL Y\", np.shape(data[ievt][im]['HCAL3_y']), \n",
    "                      \"+ HCAL E\",np.shape(data[ievt][im]['HCAL3_E']),\"= \", \"-> np.append to ECAL ->\",np.shape(event))\n",
    "            \n",
    "            event = np.insert(event, 3, depths,axis=1)\n",
    "            event = np.insert(event, 4, data[ievt][im]['boundary'][0]*np.ones(len(event)),axis=1)\n",
    "            #FIXME: use num_global_features -- Number of additional features to be \n",
    "            #concatenated with the latent space observables to form the input to F.\n",
    "            event = np.insert(event, 5, data[ievt][im]['boundary'][1]*np.ones(len(event)),axis=1)\n",
    "            \n",
    "            X_awk.append(event)\n",
    "            trueenergy = mc_truth.item().get('true_energy') #TARGET\n",
    "            Y += [trueenergy]\n",
    "            \n",
    "X_awk.end_list()\n",
    "\n",
    "X = awk_to_numpy_padded(X_awk,fill_val,ncell_max,cell_axis)\n",
    "Y = np.array(Y)\n",
    "print(\"X shape =\",np.shape(X),\"([Images X Events][Cells][XYEDBB])\") #X,Y,Energy,Depth,Boundary,Boundary\n",
    "print(\"Y shape =\",np.shape(Y),\"[MC Truth Energy]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d789e8-39ba-46bb-a4ee-30e455e4ac8e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e5d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.utils import data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c256e3-8b19-4b01-a5c2-9470283f04d4",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.normalize(X, axis=-1, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a37636-bb9f-461b-ac04-a57e03a9bc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X data =  False\n",
      "NaNs in Y data =  False\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    xy_avg = np.average(x[:,0:2], axis=0)\n",
    "    x[:,0:2] -= xy_avg\n",
    "    x[:,2] /= 100. #could make this smarter\n",
    "    x[:,4:6] /= 100.\n",
    "    \n",
    "#QUESTION: What's the ultimate goal of this normalization? Can we use tensorflow built in normalization tools?\n",
    "print(\"NaNs in X data = \",np.any(np.isnan(X)))\n",
    "print(\"NaNs in Y data = \",np.any(np.isnan(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "799d9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=0.2, test=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed65355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably want to standardize the input and output energies, or at least put them in units where the mean is O(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0e3ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, None, 6)]    0           []                               \n",
      "                                                                                                  \n",
      " tdist_0 (TimeDistributed)      (None, None, 100)    700         ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, 100)    0           ['tdist_0[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_1 (TimeDistributed)      (None, None, 100)    10100       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, 100)    0           ['tdist_1[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_2 (TimeDistributed)      (None, None, 128)    12928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " mask (Lambda)                  (None, None)         0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, 128)    0           ['tdist_2[0][0]']                \n",
      "                                                                                                  \n",
      " sum (Dot)                      (None, 128)          0           ['mask[0][0]',                   \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_0 (Dense)                (None, 100)          12900       ['sum[0][0]']                    \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 100)          0           ['dense_0[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          10100       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          10100       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 100)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            101         ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 1)            0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 56,929\n",
      "Trainable params: 56,929\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100)\n",
    "output_act, output_dim = 'linear', 1\n",
    "loss = 'mse' #mean-squared error\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes, \n",
    "          output_act=output_act, output_dim=output_dim, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 07:49:22.593248: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 207ms/step - loss: 55395573760.0000 - acc: 0.0000e+00 - val_loss: 6065249280.0000 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 9112437760.0000 - acc: 0.0000e+00 - val_loss: 6930205696.0000 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 3970250496.0000 - acc: 0.0000e+00 - val_loss: 604293824.0000 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 1790833920.0000 - acc: 0.0000e+00 - val_loss: 2431522560.0000 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1508014976.0000 - acc: 0.0000e+00 - val_loss: 80275248.0000 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 558144384.0000 - acc: 0.0000e+00 - val_loss: 1235257728.0000 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 863860544.0000 - acc: 0.0000e+00 - val_loss: 13146307.0000 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 116954696.0000 - acc: 0.0000e+00 - val_loss: 605769728.0000 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 563306496.0000 - acc: 0.0000e+00 - val_loss: 150386688.0000 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 77701800.0000 - acc: 0.0000e+00 - val_loss: 212626912.0000 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 300021632.0000 - acc: 0.0000e+00 - val_loss: 255246640.0000 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 146301936.0000 - acc: 0.0000e+00 - val_loss: 27971324.0000 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 105599968.0000 - acc: 0.0000e+00 - val_loss: 234037856.0000 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 172592992.0000 - acc: 0.0000e+00 - val_loss: 3170549.2500 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 25517358.0000 - acc: 0.0000e+00 - val_loss: 140780144.0000 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 133386096.0000 - acc: 0.0000e+00 - val_loss: 34240184.0000 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 18349764.0000 - acc: 0.0000e+00 - val_loss: 59304856.0000 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 77866032.0000 - acc: 0.0000e+00 - val_loss: 52963112.0000 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 27973924.0000 - acc: 0.0000e+00 - val_loss: 17230124.0000 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 37072896.0000 - acc: 0.0000e+00 - val_loss: 51266284.0000 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 31494394.0000 - acc: 0.0000e+00 - val_loss: 2377131.5000 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 15494313.0000 - acc: 0.0000e+00 - val_loss: 38566304.0000 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 27313736.0000 - acc: 0.0000e+00 - val_loss: 11629.4736 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 6436529.5000 - acc: 0.0000e+00 - val_loss: 26018660.0000 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 20521018.0000 - acc: 0.0000e+00 - val_loss: 726650.8750 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 3177279.7500 - acc: 0.0000e+00 - val_loss: 16371469.0000 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 14290074.0000 - acc: 0.0000e+00 - val_loss: 1266394.6250 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1935605.7500 - acc: 0.0000e+00 - val_loss: 10451316.0000 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 9617587.0000 - acc: 0.0000e+00 - val_loss: 1335676.3750 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 1325386.2500 - acc: 0.0000e+00 - val_loss: 6670249.0000 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 6432969.5000 - acc: 0.0000e+00 - val_loss: 948759.6875 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 909576.8750 - acc: 0.0000e+00 - val_loss: 4594097.5000 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 4293187.5000 - acc: 0.0000e+00 - val_loss: 584516.1250 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 615994.2500 - acc: 0.0000e+00 - val_loss: 3109580.0000 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 2849654.5000 - acc: 0.0000e+00 - val_loss: 237064.5312 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 447963.8438 - acc: 0.0000e+00 - val_loss: 2272920.7500 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 1873649.2500 - acc: 0.0000e+00 - val_loss: 69368.8906 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 384542.4062 - acc: 0.0000e+00 - val_loss: 1566348.7500 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 1187604.3750 - acc: 0.0000e+00 - val_loss: 11245.9414 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 352061.5312 - acc: 0.0000e+00 - val_loss: 1077392.7500 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 688717.1250 - acc: 0.0000e+00 - val_loss: 53952.4805 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 336405.2812 - acc: 0.0000e+00 - val_loss: 607635.6250 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 358076.4375 - acc: 0.0000e+00 - val_loss: 150737.5469 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 319583.7188 - acc: 0.0000e+00 - val_loss: 317295.6250 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 161746.6250 - acc: 0.0000e+00 - val_loss: 196929.1719 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 278734.6250 - acc: 0.0000e+00 - val_loss: 98952.7500 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 71478.0938 - acc: 0.0000e+00 - val_loss: 232903.0938 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 210065.9062 - acc: 0.0000e+00 - val_loss: 22278.2773 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 50522.7461 - acc: 0.0000e+00 - val_loss: 173350.6250 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 129944.2500 - acc: 0.0000e+00 - val_loss: 17079.3320 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 67231.9531 - acc: 0.0000e+00 - val_loss: 113743.6016 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 64100.4297 - acc: 0.0000e+00 - val_loss: 42112.3008 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 68891.3672 - acc: 0.0000e+00 - val_loss: 34483.3867 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 26952.5723 - acc: 0.0000e+00 - val_loss: 64836.9688 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 56451.9414 - acc: 0.0000e+00 - val_loss: 12412.6748 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 21519.5195 - acc: 0.0000e+00 - val_loss: 44125.4258 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 35145.5312 - acc: 0.0000e+00 - val_loss: 16280.9629 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 27633.0352 - acc: 0.0000e+00 - val_loss: 28526.5059 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 17636.8438 - acc: 0.0000e+00 - val_loss: 22281.8477 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 29506.3633 - acc: 0.0000e+00 - val_loss: 11453.1621 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 15191.2451 - acc: 0.0000e+00 - val_loss: 30526.6191 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 22699.0098 - acc: 0.0000e+00 - val_loss: 10907.4883 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 18162.9629 - acc: 0.0000e+00 - val_loss: 15978.8623 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 14093.8174 - acc: 0.0000e+00 - val_loss: 18890.8594 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 20333.8047 - acc: 0.0000e+00 - val_loss: 11998.7441 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 13698.2354 - acc: 0.0000e+00 - val_loss: 17085.6270 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 17956.9355 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=100,\n",
    "        batch_size=100,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfn.layers\n",
    "mypreds = pfn.predict(X_test,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f69ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,mypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a30507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test)\n",
    "print(mypreds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
