{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45f244a-0aa6-4879-9951-2415c4e09b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from energyflow.archs import PFN\n",
    "import training_functions\n",
    "from training_functions import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b88130-8914-4a35-8a9f-0a7881ac3617",
   "metadata": {},
   "source": [
    "## Train, Val, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfab4f76-5442-478d-84bd-d006601665d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filename = \"split_test.hdf5\"\n",
    "h5_file = h5.File(h5_filename,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b4cb17-f342-423c-8c14-7d0012774fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"model_output_Oct3\"  #Replace with your own variation!      \n",
    "path = \"./\"+label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f281a0-27d6-4b9a-a1a6-55bc49256c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 18:37:00.299508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/global/home/users/ftoralesacosta/user_pkg/usr/lib:/global/home/users/ftoralesacosta/user_pkg/usr/lib64:/lib:/lib64:/usr/lib:/usr/lib64\n",
      "2022-10-04 18:37:00.299534: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-04 18:37:00.300030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'train_hcal'),tf.float64)\n",
    "\n",
    "X_val = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'val_hcal'),tf.float64)\n",
    "\n",
    "X_test = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'test_hcal'),tf.float64)\n",
    "\n",
    "Y_train = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'train_mc'),tf.float64)\n",
    "\n",
    "Y_val = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'val_mc'),tf.float64)\n",
    "\n",
    "Y_test = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'test_mc'),tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e70f2e-88fe-4e5f-b6ad-08d20898e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_dataset = Y_train\n",
    "#scalar_from_generator(tf_dataset,10,100)                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1b9cc-c3c7-4fc2-b090-1d5d1b2b8dbb",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041285cb-b632-4241-9927-7c9d907db9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = h5_file['train_hcal'].shape[-1]\n",
    "learning_rate = 1e-4\n",
    "dropout_rate = 0.1\n",
    "batch_size = 1000\n",
    "N_Epochs = 400\n",
    "patience = 20\n",
    "N_Latent = 128\n",
    "shuffle_split = True #Turn FALSE for images!\n",
    "train_shuffle = True #Turn TRUE for images!\n",
    "Y_scalar = True\n",
    "loss = 'mse' #'mae' #'swish'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5aed6-8022-42eb-82e7-f1c25f4efa46",
   "metadata": {},
   "source": [
    "## Define Model + CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f77c2f-799c-4f84-bda4-cd0d2ae1d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, None, 1861)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " tdist_0 (TimeDistributed)      (None, None, 100)    186200      ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, 100)    0           ['tdist_0[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_1 (TimeDistributed)      (None, None, 100)    10100       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, 100)    0           ['tdist_1[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_2 (TimeDistributed)      (None, None, 128)    12928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " mask (Lambda)                  (None, None)         0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, 128)    0           ['tdist_2[0][0]']                \n",
      "                                                                                                  \n",
      " sum (Dot)                      (None, 128)          0           ['mask[0][0]',                   \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " sum_dropout (Dropout)          (None, 128)          0           ['sum[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_0 (Dense)                (None, 100)          12900       ['sum_dropout[0][0]']            \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 100)          0           ['dense_0[0][0]']                \n",
      "                                                                                                  \n",
      " dense_0_dropout (Dropout)      (None, 100)          0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          10100       ['dense_0_dropout[0][0]']        \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1_dropout (Dropout)      (None, 100)          0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          10100       ['dense_1_dropout[0][0]']        \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 100)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2_dropout (Dropout)      (None, 100)          0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            101         ['dense_2_dropout[0][0]']        \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 1)            0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 242,429\n",
      "Trainable params: 242,429\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Phi_sizes, F_sizes = (100, 100, N_Latent), (100, 100, 100)\n",
    "output_act, output_dim = 'linear', 1 #Train to predict error\n",
    "\n",
    "pfn = PFN(input_dim=input_dim, \n",
    "          Phi_sizes=Phi_sizes, \n",
    "          F_sizes=F_sizes, \n",
    "          output_act=output_act, \n",
    "          output_dim=output_dim, \n",
    "          loss=loss, \n",
    "          latent_dropout=dropout_rate,\n",
    "          F_dropouts=dropout_rate,\n",
    "          optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d00b35-35e4-45a6-ac24-12135e95ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decay,verbose=0)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb103b10-3554-45d7-a16b-c0d05c3d3f4f",
   "metadata": {},
   "source": [
    "Tensorflow needs a generator that returns a tuple (train, target), so I'm trying the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eea7cd2-93fa-4cee-a99d-220142146eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=<unknown>, dtype=tf.float64, name=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator = tf.data.Dataset.from_generator(\n",
    "    train_target_generator(h5_filename,'train_hcal','train_mc'),tf.float64)\n",
    "\n",
    "val_generator = tf.data.Dataset.from_generator(\n",
    "    train_target_generator(h5_filename,'train_hcal','train_mc'),tf.float64)\n",
    "\n",
    "training_generator.batch(batch_size)\n",
    "val_generator.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa1b75c1-25e9-44b5-999c-c8010d38c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for data in val_generator.batch(1000):\n",
    "#    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73467744-b7af-4fbe-be24-f47ebdbd090b",
   "metadata": {},
   "source": [
    "# FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365d966d-5bbd-40b6-8b17-c580858f1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 891, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 848, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=mse, and therefore expects target data to be provided in `fit()`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m the_fit \u001b[38;5;241m=\u001b[39m \u001b[43mpfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_Epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_shuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tin/lib/python3.9/site-packages/energyflow/archs/archbase.py:370\u001b[0m, in \u001b[0;36mNNBase.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\u001b[38;5;241m.\u001b[39mextend(callbacks)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# do the fitting\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# handle saving at the end, if we weren't already saving throughout \u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_while_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/tin/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file79h2bkhg.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 891, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"/global/home/users/ftoralesacosta/anaconda3/envs/tin/lib/python3.9/site-packages/keras/engine/training.py\", line 848, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=mse, and therefore expects target data to be provided in `fit()`.\n"
     ]
    }
   ],
   "source": [
    "the_fit = pfn.fit(training_generator,\n",
    "                  epochs=N_Epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[lr_scheduler, early_stopping],\n",
    "                  shuffle=train_shuffle,\n",
    "                  validation_data=val_generator,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec4cd411-d214-4ac7-93d5-a12bb8869bac",
   "metadata": {},
   "source": [
    "the_fit = pfn.fit((X_train, Y_train),\n",
    "                  epochs=N_Epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[lr_scheduler, early_stopping],\n",
    "                  shuffle=train_shuffle,\n",
    "                  validation_data=val_generator,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a65ce-e7bf-4aad-ae97-b8ac2866f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfn.layers\n",
    "pfn.save(\"%s/energy_regression.h5\"%(path))\n",
    "mypreds = pfn.predict(X_test,batch_size=400)\n",
    "\n",
    "if (Y_scalar):\n",
    "    mypreds = mypreds*Y_StDev + Y_Mean\n",
    "    Y_test  =  Y_test*Y_StDev + Y_Mean\n",
    "    \n",
    "np.save(\"%s/predictions.npy\"%(path),mypreds)\n",
    "np.save(\"%s/y_test.npy\"%(path),Y_test)\n",
    "np.save(\"%s/x_test.npy\"%(path),X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205bbfe-2f53-46f7-8b42-c73b4eef6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = X_train\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for data,ibatch in zip(tf_dataset.batch(1000),range(0,100)):\n",
    "    scaler.partial_fit(data.numpy().transpose(0,2,1).reshape(-1,4))\n",
    "    print(\"mean = \",scaler.mean_,\"+/-\",np.sqrt(scaler.var_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a4411-11e5-45d2-a9fc-e1810da07035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dict for train,test,val mean and stdev. Also for target/labels. Remember, dataset needs to return tuple of (input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38629a4f-7f66-4043-af9b-aebc450bac89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_codesign",
   "language": "python",
   "name": "tin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
