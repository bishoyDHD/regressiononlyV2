{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45f244a-0aa6-4879-9951-2415c4e09b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from energyflow.archs import PFN\n",
    "import training_functions\n",
    "from training_functions import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b88130-8914-4a35-8a9f-0a7881ac3617",
   "metadata": {},
   "source": [
    "## Train, Val, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfab4f76-5442-478d-84bd-d006601665d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_filename = \"split_test.hdf5\"\n",
    "h5_file = h5.File(h5_filename,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b4cb17-f342-423c-8c14-7d0012774fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"model_output_Oct3\"  #Replace with your own variation!      \n",
    "path = \"./\"+label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f281a0-27d6-4b9a-a1a6-55bc49256c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 16:45:10.010962: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/global/home/users/ftoralesacosta/user_pkg/usr/lib:/global/home/users/ftoralesacosta/user_pkg/usr/lib64:/lib:/lib64:/usr/lib:/usr/lib64\n",
      "2022-10-05 16:45:10.010988: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-05 16:45:10.011817: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'train_hcal'),tf.float64)\n",
    "\n",
    "X_val = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'val_hcal'),tf.float64)\n",
    "\n",
    "X_test = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'test_hcal'),tf.float64)\n",
    "\n",
    "Y_train = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'train_mc'),tf.float64)\n",
    "\n",
    "Y_val = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'val_mc'),tf.float64)\n",
    "\n",
    "Y_test = tf.data.Dataset.from_generator(\n",
    "    generator(h5_filename,'test_mc'),tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e70f2e-88fe-4e5f-b6ad-08d20898e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_dataset = Y_train\n",
    "#scalar_from_generator(tf_dataset,10,100)                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1b9cc-c3c7-4fc2-b090-1d5d1b2b8dbb",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041285cb-b632-4241-9927-7c9d907db9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = h5_file['train_hcal'].shape[-2] #should be 4: Cell E,X,Y,Z, the number of features per particle\n",
    "learning_rate = 1e-4\n",
    "dropout_rate = 0.1\n",
    "batch_size = 1000\n",
    "N_Epochs = 400\n",
    "patience = 20\n",
    "N_Latent = 128\n",
    "shuffle_split = True #Turn FALSE for images!\n",
    "train_shuffle = True #Turn TRUE for images!\n",
    "Y_scalar = True\n",
    "loss = 'mse' #'mae' #'swish'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5aed6-8022-42eb-82e7-f1c25f4efa46",
   "metadata": {},
   "source": [
    "## Define Model + CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88f77c2f-799c-4f84-bda4-cd0d2ae1d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, None, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " tdist_0 (TimeDistributed)      (None, None, 100)    500         ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, 100)    0           ['tdist_0[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_1 (TimeDistributed)      (None, None, 100)    10100       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, 100)    0           ['tdist_1[0][0]']                \n",
      "                                                                                                  \n",
      " tdist_2 (TimeDistributed)      (None, None, 128)    12928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " mask (Lambda)                  (None, None)         0           ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, 128)    0           ['tdist_2[0][0]']                \n",
      "                                                                                                  \n",
      " sum (Dot)                      (None, 128)          0           ['mask[0][0]',                   \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " sum_dropout (Dropout)          (None, 128)          0           ['sum[0][0]']                    \n",
      "                                                                                                  \n",
      " dense_0 (Dense)                (None, 100)          12900       ['sum_dropout[0][0]']            \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 100)          0           ['dense_0[0][0]']                \n",
      "                                                                                                  \n",
      " dense_0_dropout (Dropout)      (None, 100)          0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          10100       ['dense_0_dropout[0][0]']        \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1_dropout (Dropout)      (None, 100)          0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          10100       ['dense_1_dropout[0][0]']        \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 100)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2_dropout (Dropout)      (None, 100)          0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            101         ['dense_2_dropout[0][0]']        \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 1)            0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 56,729\n",
      "Trainable params: 56,729\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Phi_sizes, F_sizes = (100, 100, N_Latent), (100, 100, 100)\n",
    "output_act, output_dim = 'linear', 1 #Train to predict error\n",
    "\n",
    "pfn = PFN(input_dim=input_dim, \n",
    "          Phi_sizes=Phi_sizes, \n",
    "          F_sizes=F_sizes, \n",
    "          output_act=output_act, \n",
    "          output_dim=output_dim, \n",
    "          loss=loss, \n",
    "          latent_dropout=dropout_rate,\n",
    "          F_dropouts=dropout_rate,\n",
    "          optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d00b35-35e4-45a6-ac24-12135e95ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_decay,verbose=0)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb103b10-3554-45d7-a16b-c0d05c3d3f4f",
   "metadata": {},
   "source": [
    "Tensorflow needs a generator that returns a tuple (train, target), so I'm trying the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eea7cd2-93fa-4cee-a99d-220142146eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, None, None, None), dtype=tf.float64, name=None), TensorSpec(shape=(None, None), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator = tf.data.Dataset.from_generator(\n",
    "    train_target_generator(h5_filename,'train_hcal','train_mc'),\n",
    "    output_shapes=(tf.TensorShape([None,None,None]),[None]),\n",
    "    output_types=(tf.float64, tf.float64))\n",
    "\n",
    "val_generator = tf.data.Dataset.from_generator(\n",
    "    train_target_generator(h5_filename,'val_hcal','val_mc'),\n",
    "    output_shapes=(tf.TensorShape([None,None,None]),[None]),\n",
    "    output_types=(tf.float64, tf.float64))\n",
    "\n",
    "training_generator.batch(batch_size)\n",
    "val_generator.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa1b75c1-25e9-44b5-999c-c8010d38c775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 1861, 4)\n"
     ]
    }
   ],
   "source": [
    "for data in training_generator.batch(batch_size):\n",
    "    print(np.shape(data[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73467744-b7af-4fbe-be24-f47ebdbd090b",
   "metadata": {},
   "source": [
    "# FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d966d-5bbd-40b6-8b17-c580858f1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "   5926/Unknown - 80s 13ms/step - loss: 2305.2048 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "the_fit = pfn.fit(\n",
    "    training_generator,\n",
    "    epochs=N_Epochs,\n",
    "    batch_size=batch_size,    \n",
    "    callbacks=[lr_scheduler, early_stopping],\n",
    "    validation_data=val_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a65ce-e7bf-4aad-ae97-b8ac2866f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfn.layers\n",
    "pfn.save(\"%s/energy_regression.h5\"%(path))\n",
    "mypreds = pfn.predict(X_test,batch_size=400)\n",
    "\n",
    "if (Y_scalar):\n",
    "    mypreds = mypreds*target_stdevs[0] + target_means[0]\n",
    "    Y_test  =  Y_test*target_stdevs[0] + target_means[0]\n",
    "    #0 index = E, 1 index = Theta\n",
    "    \n",
    "np.save(\"%s/predictions.npy\"%(path),mypreds)\n",
    "np.save(\"%s/y_test.npy\"%(path),Y_test)\n",
    "np.save(\"%s/x_test.npy\"%(path),X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205bbfe-2f53-46f7-8b42-c73b4eef6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = X_train\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for data,ibatch in zip(tf_dataset.batch(1000),range(0,100)):\n",
    "    scaler.partial_fit(data.numpy().transpose(0,2,1).reshape(-1,4))\n",
    "    print(\"mean = \",scaler.mean_,\"+/-\",np.sqrt(scaler.var_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a4411-11e5-45d2-a9fc-e1810da07035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dict for train,test,val mean and stdev. Also for target/labels. Remember, dataset needs to return tuple of (input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38629a4f-7f66-4043-af9b-aebc450bac89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_codesign",
   "language": "python",
   "name": "tin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
