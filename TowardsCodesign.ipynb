{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10683b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77919377",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pionplus_1k.npy'\n",
    "file = open(filename, 'rb')\n",
    "mc_truth = np.load(file,allow_pickle=True) #Added Generator E and Angle\n",
    "data = np.load(file,allow_pickle=True)\n",
    "\n",
    "test_file = open('test.npy', 'rb')\n",
    "test_data = np.load(test_file,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9967b0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- ORIGINAL test.npy -------------------\n",
      "number of images in event 400\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------- ORIGINAL test.npy -------------------\")\n",
    "print('number of images in event', len(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f22c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- NEW .npy ----------------\n",
      "number of images in event 400\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------- NEW .npy ----------------\")\n",
    "print('number of images in event', len(data[0]))\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0898d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.007061"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_truth.item().get('true_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a86edf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images in event 400\n",
      "(400, 96, 6)\n"
     ]
    }
   ],
   "source": [
    "#============ Original ============================\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "with open('test.npy', 'rb') as f:#wrong file for now\n",
    "#with open(filename, 'rb') as f:\n",
    "    data = np.load(f,allow_pickle=True)\n",
    "    ievt = 0\n",
    "    print('number of images in event', len(data[ievt]))\n",
    "    ## Here we loop over all \"images\", which are created by integrating HCAL sampling layers defing 3 sectors defined \n",
    "    ## by two z position that define boundary. Note for all images ECAL is the same (no longitudinal separation in ECAL)\n",
    "    for im in range(len(data[ievt])):\n",
    "        event = np.c_[data[ievt][im]['HCAL1_x'][0],data[ievt][im]['HCAL1_y'][0],data[ievt][im]['HCAL1_E'][0]]\n",
    "        depths = np.array([2*np.ones(len(data[ievt][im]['HCAL1_x'][0]))]).flatten()\n",
    "        if (len(data[ievt][im]['HCAL2_x'])>0):\n",
    "            event = np.concatenate([event,np.c_[data[ievt][im]['HCAL2_x'][0],data[ievt][im]['HCAL2_y'][0],data[ievt][im]['HCAL2_E'][0]]])\n",
    "            depths = np.concatenate([depths,np.array([3*np.ones(len(data[ievt][im]['HCAL2_x'][0]))]).flatten()])\n",
    "        if (len(data[ievt][im]['HCAL3_x'])>0):\n",
    "            event = np.concatenate([event,np.c_[data[ievt][im]['HCAL3_x'][0],data[ievt][im]['HCAL3_y'][0],data[ievt][im]['HCAL3_E'][0]]])\n",
    "            depths = np.concatenate([depths,np.array([4*np.ones(len(data[ievt][im]['HCAL3_x'][0]))]).flatten()])\n",
    "        event = np.concatenate([event,np.c_[data[ievt][im]['ECAL_x'],data[ievt][im]['ECAL_y'],data[ievt][im]['ECAL_E']]])\n",
    "        depths = np.concatenate([depths,np.array([1*np.ones(len(data[ievt][im]['ECAL_x']))]).flatten()])\n",
    "        event = np.insert(event, 3, depths,axis=1)\n",
    "        event = np.insert(event, 4, data[ievt][im]['boundary'][0]*np.ones(len(event)),axis=1) #better to make these global features, but I did not want to download the latest energyflow package\n",
    "        event = np.insert(event, 5, data[ievt][im]['boundary'][1]*np.ones(len(event)),axis=1)\n",
    "        X += [event]\n",
    "        trueenergy = 1. #Miguel, please add this!\n",
    "        Y += [trueenergy]\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b832c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of events:  1000\n",
      "number of \"images\" per event:  400\n",
      "ECAL X: (311,) + ECAL Y (311,) + ECAL E (311,) = (311, 3) [using np.c_]\n",
      "HCAL X: (1, 169) + HCAL Y (1, 169) + HCAL E (1, 169) =  -> np.append to ECAL -> (591, 3)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "X = ak.ArrayBuilder()\n",
    "X.begin_list()\n",
    "#builder.begin_list()\n",
    "#builder.append(x)\n",
    "#builder.append(y)\n",
    "#builder.append(z)\n",
    "#builder.end_list()\n",
    "with open(filename, 'rb') as f:\n",
    "#with open(\"test.npy\", 'rb') as f:\n",
    "    mc_truth = np.load(f,allow_pickle=True)\n",
    "    data = np.load(f,allow_pickle=True)\n",
    "    \n",
    "    print('number of events: ', len(data))\n",
    "    print('number of \"images\" per event: ', len(data[0]))\n",
    "    \n",
    "    ievt=0\n",
    "    #if (ievt!=-99): #place holder to maintain indents...\n",
    "    #for ievt in range(0,len(data)):\n",
    "    for ievt in range(0,20):\n",
    "        \n",
    "        ## Here we loop over all events and then all \"images\", which are created by integrating HCAL sampling layers defing 3 sectors defined \n",
    "        ## by two z position that define boundary. Note for all images ECAL is the same (no longitudinal separation in ECAL)\n",
    "\n",
    "        for im in range(len(data[ievt])):\n",
    "            #FIXME: assumes ECAL is always hit\n",
    "            event = np.c_[data[ievt][im]['ECAL_x'],data[ievt][im]['ECAL_y'],data[ievt][im]['ECAL_E']]\n",
    "            depths = np.array([1*np.ones(len(data[ievt][im]['ECAL_x']))]).flatten()\n",
    "            \n",
    "            if (ievt == im == 0):\n",
    "                print(\"ECAL X:\", np.shape(data[ievt][im]['ECAL_x']), \"+ ECAL Y\", np.shape(data[ievt][im]['ECAL_y']),\n",
    "                  \"+ ECAL E\", np.shape(data[ievt][im]['ECAL_E']),\"=\",np.shape(event), \"[using np.c_]\")\n",
    "\n",
    "            if (len(data[ievt][im]['HCAL1_x'])>0):\n",
    "                event = np.concatenate([event,np.c_[data[ievt][im]['HCAL1_x'][0],data[ievt][im]['HCAL1_y'][0],data[ievt][im]['HCAL1_E'][0]]])\n",
    "                depths = np.concatenate([depths,np.array([2*np.ones(len(data[ievt][im]['HCAL1_x'][0]))]).flatten()])\n",
    "            \n",
    "            if (len(data[ievt][im]['HCAL2_x'])>0):\n",
    "                event = np.concatenate([event,np.c_[data[ievt][im]['HCAL2_x'][0],data[ievt][im]['HCAL2_y'][0],data[ievt][im]['HCAL2_E'][0]]])\n",
    "                depths = np.concatenate([depths,np.array([3*np.ones(len(data[ievt][im]['HCAL2_x'][0]))]).flatten()])\n",
    "                \n",
    "            if (len(data[ievt][im]['HCAL3_x'])>0):\n",
    "                event = np.concatenate([event,np.c_[data[ievt][im]['HCAL3_x'][0],data[ievt][im]['HCAL3_y'][0],data[ievt][im]['HCAL3_E'][0]]])\n",
    "                depths = np.concatenate([depths,np.array([4*np.ones(len(data[ievt][im]['HCAL3_x'][0]))]).flatten()])\n",
    "            \n",
    "            if (ievt == im == 0):\n",
    "                print(\"HCAL X:\", np.shape(data[ievt][im]['HCAL3_x']), \"+ HCAL Y\", np.shape(data[ievt][im]['HCAL3_y']), \n",
    "                      \"+ HCAL E\",np.shape(data[ievt][im]['HCAL3_E']),\"= \", \"-> np.append to ECAL ->\",np.shape(event))\n",
    "            \n",
    "            event = np.insert(event, 3, depths,axis=1)\n",
    "            event = np.insert(event, 4, data[ievt][im]['boundary'][0]*np.ones(len(event)),axis=1)\n",
    "            #FIXME: use num_global_features Number of additional features to be \n",
    "            #concatenated with the latent space observables to form the input to F.\n",
    "            event = np.insert(event, 5, data[ievt][im]['boundary'][1]*np.ones(len(event)),axis=1)\n",
    "            \n",
    "            #X += [event]\n",
    "            X.append(event)\n",
    "            #np.append(X,event)\n",
    "            trueenergy = mc_truth.item().get('true_energy') #TARGET, right?\n",
    "            Y += [trueenergy]\n",
    "\n",
    "            \n",
    "X.end_list()    \n",
    "#X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print(\"Y shape =\",np.shape(Y),\"[MC Truth Energy]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncell_max = 1200 #Root file indicase avg. of ~270 per ECal, per HCal, event. \n",
    "cell_axis = 2\n",
    "fill_val = 0\n",
    "fill_val = np.zeros(6)\n",
    "print(fill_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bdefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ak.to_list(X.snapshot()))\n",
    "#print(ak.max(X))\n",
    "#ak.count(X)\n",
    "\n",
    "#ak.to_numpy(ak.pad_none(X, ncell_max, axis=cell_axis,clip=True)) #padding awkward array\n",
    "#ak.fill_none(ak.pad_none(X, ncell_max, axis=cell_axis, clip=True), fill_val)\n",
    "#testX = ak.fill_none(ak.pad_none(X, ncell_max, axis=cell_axis, clip=True), 999)\n",
    "#Stack: np.asarray(ak.fill_none(ak.pad_none(X, 2, clip=True), 999))\n",
    "#X = np.asarray(ak.fill_none(ak.pad_none(ak.ArrayBuilder.snapshot(X), ncell_max, axis=cell_axis, clip=True), fill_val,axis=cell_axis))\n",
    "\n",
    "padded = ak.pad_none(ak.ArrayBuilder.snapshot(X), ncell_max, axis=cell_axis, clip=True)\n",
    "none_to_0 = ak.fill_none(padded,fill_val,axis=cell_axis)\n",
    "test = ak.to_numpy(none_to_0[0][700][1100])\n",
    "print(test)\n",
    "print(type(X))\n",
    "print(type(padded))\n",
    "print(type(none_to_0))\n",
    "\n",
    "#print(none_to_0[0])\n",
    "array = ak.to_numpy(none_to_0)\n",
    "print(np.shape(np.squeeze(array)))\n",
    "\n",
    "X = np.squeeze(array)\n",
    "print(np.shape(X))\n",
    "\n",
    "#X = np.squeeze(X)\n",
    "#print(\"X shape =\",np.shape(X),\"([Images X Events][Cells][XYEDBB])\") #X,Y,Energy,Depth,Boundary,Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.utils import data_split\n",
    "#see https://energyflow.network/examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c256e3-8b19-4b01-a5c2-9470283f04d4",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.normalize(X, axis=-1, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a37636-bb9f-461b-ac04-a57e03a9bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  np.copy(X) # workaround: output array is read-only\n",
    "for x in X:\n",
    "    xy_avg = np.average(x[:,0:2], axis=0)\n",
    "    x[:,0:2] -= xy_avg\n",
    "    x[:,2] /= 100. #could make this smarter\n",
    "    x[:,4:6] /= 100.\n",
    "    \n",
    "#QUESTION: What's the ultimate goal of this normalization? Can we use tensorflow built in normalization tools?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eec626-6700-4c85-8472-d4f88bef1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=0.2, test=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed65355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably want to standardize the input and output energies, or at least put them in units where the mean is O(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e3ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Phi_sizes, F_sizes = (100, 100, 128), (100, 100, 100)\n",
    "output_act, output_dim = 'linear', 1\n",
    "loss = 'mse' #mean-squared error\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes, \n",
    "          output_act=output_act, output_dim=output_dim, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=100,\n",
    "        batch_size=100,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfn.layers\n",
    "mypreds = pfn.predict(X_test,batch_size=100)\n",
    "print(np.shape(mypreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f69ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test,mypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c86246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#????????!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a30507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test)\n",
    "print(mypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2551c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
